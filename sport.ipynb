{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34821dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T16:43:22.263464600Z",
     "start_time": "2023-12-27T16:43:13.427654400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702c4ee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T16:44:21.820318800Z",
     "start_time": "2023-12-27T16:43:41.306427100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['barbell biceps curl', 'bench press', 'chest fly machine', 'deadlift', 'decline bench press', 'hammer curl', 'hip thrust', 'incline bench press', 'lat pulldown', 'lateral raise', 'leg extension', 'leg raises', 'plank', 'pull Up', 'push-up', 'romanian deadlift', 'russian twist', 'shoulder press', 'squat', 't bar row', 'tricep Pushdown', 'tricep dips']\n"
     ]
    }
   ],
   "source": [
    "# Directory where videos are stored\n",
    "DATA_DIR = \"data/sport\"\n",
    "\n",
    "# Mapping classes\n",
    "classes = sorted(os.listdir(DATA_DIR))  # Assuming folder names are class names\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "# Load videos and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in classes:\n",
    "    videos = os.listdir(os.path.join(DATA_DIR, category))\n",
    "    for video in videos:\n",
    "        video_path = os.path.join(DATA_DIR, category, video)\n",
    "        # You might want to extract features or frames from videos here\n",
    "        # For example, capturing one frame for simplicity\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (224, 224))  # Resizing to a fixed size\n",
    "            data.append(frame)\n",
    "            labels.append(classes.index(category))\n",
    "        cap.release()\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9ca61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:37:58.905648100Z",
     "start_time": "2023-12-27T17:37:58.568006400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "data = data / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "labels = to_categorical(labels, num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3360caf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:38:07.275743700Z",
     "start_time": "2023-12-27T17:38:07.038468600Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ce7f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:38:19.949080400Z",
     "start_time": "2023-12-27T17:38:19.071133Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96821e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:39:58.614786400Z",
     "start_time": "2023-12-27T17:38:25.153084100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 7s 381ms/step - loss: 7.3292 - accuracy: 0.0710 - val_loss: 3.0720 - val_accuracy: 0.1069\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 2.9843 - accuracy: 0.1171 - val_loss: 2.8445 - val_accuracy: 0.1145\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 2.5241 - accuracy: 0.2610 - val_loss: 2.6470 - val_accuracy: 0.3206\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 1.7040 - accuracy: 0.5547 - val_loss: 2.4498 - val_accuracy: 0.3130\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.8073 - accuracy: 0.8042 - val_loss: 2.3125 - val_accuracy: 0.3817\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.3003 - accuracy: 0.9386 - val_loss: 2.4346 - val_accuracy: 0.4275\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0865 - accuracy: 0.9923 - val_loss: 2.6449 - val_accuracy: 0.4351\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0307 - accuracy: 0.9981 - val_loss: 3.0976 - val_accuracy: 0.4046\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 6s 369ms/step - loss: 0.0149 - accuracy: 0.9981 - val_loss: 2.6007 - val_accuracy: 0.4504\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.8788 - val_accuracy: 0.4198\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7720cc76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:40:03.912751Z",
     "start_time": "2023-12-27T17:40:02.106769300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 66ms/step - loss: 2.8788 - accuracy: 0.4198\n",
      "Test accuracy: 41.98473393917084%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "444256e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:46:32.763571Z",
     "start_time": "2023-12-27T17:46:31.086277700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrysalis/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"sport_model.h5\"\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc85a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
